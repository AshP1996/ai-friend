# class AudioManager:
#     """
#     Central Voice Controller
#     - Receives PCM stream
#     - Produces partial & final STT
#     - Generates TTS audio bytes
#     """

#     def __init__(self):
#         self.logger = Logger("AudioManager")
#         self.stt = SpeechToText()
#         self.tts = TextToSpeech()
#         self.active = True

#     # âœ… ADD THIS
#     def initialize(self):
#         """
#         Compatibility init hook.
#         Streaming STT initializes lazily.
#         """
#         self.logger.info("ğŸ§ AudioManager initialized")

#     # ===============================
#     # PCM STREAM (WebSocket)
#     # ===============================
#     # def process_pcm(self, pcm_bytes: bytes) -> Dict:
#     #     self.logger.info(f"ğŸ§ PCM chunk received: {len(pcm_bytes)} bytes")

#     #     if not self.active:
#     #         return {"partial": None, "final": None}

#     #     return self.stt.stream(pcm_bytes)

#     def process_pcm(self, pcm_bytes: bytes) -> Dict:
#         self.logger.warning(f"ğŸ§ PCM RECEIVED: {len(pcm_bytes)} bytes")
#         return self.stt.stream(pcm_bytes)
#     # ===============================
#     # TEXT â†’ SPEECH
#     # ===============================
#     async def text_to_speech(self, text: str, emotion: str = "neutral") -> bytes:
#         if not text:
#             return b""

#         return await self.tts.generate_audio_bytes(text, emotion)

#     # ===============================
#     # RESET / SHUTDOWN
#     # ===============================
#     def reset(self):
#         self.stt.reset()

#     def shutdown(self):
#         self.active = False
#         self.reset()
from typing import Dict
from utils.logger import Logger
from voice.speech_to_text import SpeechToText
from voice.text_to_speech import TextToSpeech


class AudioManager:
    def __init__(self):
        self.logger = Logger("AudioManager")
        self.stt = SpeechToText()
        self.tts = TextToSpeech()
        self.active = True
        self.is_speaking = False

        self.logger.info("ğŸ†• AudioManager created")

    def initialize(self):
        self.logger.info("ğŸ§ AudioManager initialized")

    # ===============================
    # PCM STREAM â†’ STT
    # ===============================
    def process_pcm(self, pcm_bytes: bytes) -> Dict:
        if not self.active:
            self.logger.warning("â›” Ignoring PCM: manager inactive")
            return {"partial": None, "final": None}

        if self.is_speaking:
            self.logger.debug("ğŸ”‡ Ignoring PCM: AI is speaking")
            return {"partial": None, "final": None}

        self.logger.debug(f"ğŸ™ï¸ PCM received: {len(pcm_bytes)} bytes")
        return self.stt.stream(pcm_bytes)

    # ===============================
    # TEXT â†’ SPEECH
    # ===============================
    async def text_to_speech(self, text: str, emotion: str = "neutral") -> bytes:
        if not text:
            self.logger.warning("âš ï¸ Empty TTS request")
            return b""

        self.is_speaking = True
        self.logger.info(f"ğŸ—£ï¸ TTS started | emotion={emotion}")

        try:
            audio = await self.tts.generate_audio_bytes(text, emotion)
            self.logger.info(f"ğŸ”Š TTS audio generated ({len(audio)} bytes)")
            return audio
        finally:
            self.is_speaking = False
            self.logger.info("ğŸ§ TTS finished, listening resumed")

    def reset(self):
        self.logger.info("ğŸ”„ STT reset")
        self.stt.reset()

    def shutdown(self):
        self.logger.info("ğŸ§¹ AudioManager shutdown")
        self.active = False
        self.reset()
